{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6DRepNet360 Head Pose Estimation Example\n",
        "\n",
        "This notebook demonstrates how to use the 6DRepNet360 model for head pose estimation on a single image.\n",
        "\n",
        "## Steps:\n",
        "1. Check GPU availability and download pre-trained model\n",
        "2. Import required libraries and modules\n",
        "3. Load and configure the model\n",
        "4. Run inference on an image\n",
        "5. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1UUl6DJXGP6"
      },
      "outputs": [],
      "source": [
        "# Step 1: Check GPU availability\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fuUXjNdX7qQ"
      },
      "outputs": [],
      "source": [
        "# Download pre-trained model\n",
        "!wget https://cloud.ovgu.de/s/TewGC9TDLGgKkmS/download -O 6DRepNet360_Full-Rotation_300W_LP+Panoptic.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oLmgbvEvbMcM"
      },
      "outputs": [],
      "source": [
        "# Step 2: Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if model file exists\n",
        "model_filename = '6DRepNet360_Full-Rotation_300W_LP+Panoptic.pth'\n",
        "model_exists = os.path.exists(model_filename) or os.path.exists(os.path.join('..', model_filename))\n",
        "\n",
        "if not model_exists:\n",
        "    print(f\"Model file '{model_filename}' not found.\")\n",
        "    print(\"Please run the download cell above.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LI173MxPeHh5"
      },
      "outputs": [],
      "source": [
        "# Import project modules\n",
        "current_dir = os.getcwd()\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "sixd_dir_path = os.path.join(parent_dir, 'sixdrepnet360')\n",
        "\n",
        "if sixd_dir_path not in sys.path:\n",
        "    sys.path.insert(0, sixd_dir_path)\n",
        "\n",
        "import utils\n",
        "from test import SixDRepNet360"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "99p_4-aPcJBm",
        "outputId": "3e1798b5-af8f-4d28-ae08-b9e460a8c53a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: 6DRepNet360_Full-Rotation_300W_LP+Panoptic.pth\n",
            "Model loaded successfully on cuda:0\n",
            "Model loaded successfully on cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Load and configure the model\n",
        "%matplotlib inline\n",
        "\n",
        "# Initialize model (ResNet-50 based)\n",
        "model = SixDRepNet360(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "# Load pre-trained weights (check both current dir and parent dir)\n",
        "model_filename = '6DRepNet360_Full-Rotation_300W_LP+Panoptic.pth'\n",
        "model_paths = [\n",
        "    model_filename,  # Current directory (examples/)\n",
        "    os.path.join('..', model_filename)  # Parent directory (project root)\n",
        "]\n",
        "\n",
        "saved_model_path = None\n",
        "for path in model_paths:\n",
        "    if os.path.exists(path):\n",
        "        saved_model_path = path\n",
        "        break\n",
        "\n",
        "if saved_model_path is None:\n",
        "    raise FileNotFoundError(f\"Model file '{model_filename}' not found in current or parent directory\")\n",
        "\n",
        "print(f\"Loading model from: {saved_model_path}\")\n",
        "\n",
        "saved_state_dict = torch.load(saved_model_path, map_location='cpu')\n",
        "model.load_state_dict(saved_state_dict)\n",
        "\n",
        "# Move to device and set to evaluation mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded successfully on {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Prepare image transformations\n",
        "transformations = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Inference Results ---\n",
            "Yaw: -63.21°\n",
            "Pitch: 166.03°\n",
            "Roll: 179.67°\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Load image and run inference\n",
        "# Replace with your image path\n",
        "image_path = '/path/to/your/image.jpg'  \n",
        "\n",
        "# Load and preprocess image\n",
        "img_pil = Image.open(image_path).convert('RGB')\n",
        "input_tensor = transformations(img_pil)\n",
        "input_tensor = input_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    R_pred = model(input_tensor)\n",
        "\n",
        "# Convert rotation matrix to Euler angles\n",
        "euler_angles = utils.compute_euler_angles_from_rotation_matrices(R_pred) * 180 / np.pi\n",
        "pitch_deg = euler_angles[0, 0].cpu().item()\n",
        "yaw_deg = euler_angles[0, 1].cpu().item()\n",
        "roll_deg = euler_angles[0, 2].cpu().item()\n",
        "\n",
        "print(\"--- Inference Results ---\")\n",
        "print(f\"Yaw: {yaw_deg:.2f}°\")\n",
        "print(f\"Pitch: {pitch_deg:.2f}°\")\n",
        "print(f\"Roll: {roll_deg:.2f}°\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: Visualize results\n",
        "cv2_img = np.array(img_pil)\n",
        "cv2_img = cv2_img[:, :, ::-1].copy()  # RGB to BGR\n",
        "\n",
        "# Draw pose axes on the image\n",
        "utils.draw_axis(cv2_img, yaw_deg, pitch_deg, roll_deg)\n",
        "\n",
        "# Display result\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.title(f\"Head Pose Estimation\\nYaw: {yaw_deg:.1f}°, Pitch: {pitch_deg:.1f}°, Roll: {roll_deg:.1f}°\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "6drepnet_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
